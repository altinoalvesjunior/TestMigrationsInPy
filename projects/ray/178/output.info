"commit_hash": "611e7d550922188586fb66693f897f5578cdfcd8",
"commit_link": "https://github.com/ray-project/ray/commit/611e7d550922188586fb66693f897f5578cdfcd8",
"files": ["rllib/BUILD", "rllib/algorithms/algorithm.py", "rllib/algorithms/algorithm_config.py", "rllib/algorithms/callbacks.py", "rllib/algorithms/dqn/dqn.py", "rllib/algorithms/dqn/dqn_rainbow_learner.py", "rllib/algorithms/impala/impala.py", "rllib/algorithms/ppo/ppo.py", "rllib/algorithms/ppo/tests/test_ppo_with_env_runner.py", "rllib/algorithms/sac/sac.py", "rllib/algorithms/tests/test_algorithm.py", "rllib/algorithms/tests/test_worker_failures.py", "rllib/core/learner/learner_group.py", "rllib/env/multi_agent_env_runner.py", "rllib/env/multi_agent_episode.py", "rllib/env/single_agent_env_runner.py", "rllib/env/tests/test_multi_agent_episode.py", "rllib/evaluate.py", "rllib/evaluation/metrics.py", "rllib/evaluation/worker_set.py", "rllib/examples/_old_api_stack/complex_struct_space.py", "rllib/examples/_old_api_stack/connectors/self_play_with_policy_checkpoint.py", "rllib/examples/_old_api_stack/custom_keras_model.py", "rllib/examples/_old_api_stack/parametric_actions_cartpole.py", "rllib/examples/_old_api_stack/parametric_actions_cartpole_embeddings_learnt_by_model.py", "rllib/examples/_old_api_stack/remote_base_env_with_custom_api.py", "rllib/examples/_old_api_stack/remote_envs_with_inference_done_on_main_node.py", "rllib/examples/_old_api_stack/sb2rllib_rllib_example.py", "rllib/examples/algorithms/custom_training_step_on_and_off_policy_combined.py", "rllib/examples/autoregressive_action_dist.py", "rllib/examples/cartpole_lstm.py", "rllib/examples/centralized_critic.py", "rllib/examples/centralized_critic_2.py", "rllib/examples/checkpoints/checkpoint_by_custom_criteria.py", "rllib/examples/checkpoints/restore_1_of_n_agents_from_checkpoint.py", "rllib/examples/connectors/mean_std_filtering.py", "rllib/examples/curriculum/curriculum_learning.py", "rllib/examples/custom_recurrent_rnn_tokenizer.py", "rllib/examples/envs/env_rendering_and_recording.py", "rllib/examples/envs/external_envs/cartpole_server.py", "rllib/examples/envs/greyscale_env.py", "rllib/examples/envs/unity3d_env_local.py", "rllib/examples/evaluation/custom_evaluation.py", "rllib/examples/evaluation/evaluation_parallel_to_training.py", "rllib/examples/gpus/fractional_gpus.py", "rllib/examples/hierarchical/hierarchical_training.py", "rllib/examples/inference/policy_inference_after_training.py", "rllib/examples/inference/policy_inference_after_training_with_attention.py", "rllib/examples/inference/policy_inference_after_training_with_lstm.py", "rllib/examples/multi_agent/custom_heuristic_policy.py", "rllib/examples/multi_agent/rock_paper_scissors_heuristic_vs_learned.py", "rllib/examples/multi_agent/self_play_league_based_with_open_spiel.py", "rllib/examples/multi_agent/self_play_with_open_spiel.py", "rllib/examples/offline_rl/custom_input_api.py", "rllib/examples/ray_tune/custom_experiment.py", "rllib/examples/ray_tune/custom_logger.py", "rllib/examples/ray_tune/custom_progress_reporter.py", "rllib/examples/replay_buffer_api.py", "rllib/execution/rollout_ops.py", "rllib/offline/estimators/tests/test_ope.py", "rllib/tests/run_regression_tests.py", "rllib/tuned_examples/dqn/cartpole_dqn_envrunner.py", "rllib/tuned_examples/ppo/cartpole_ppo_envrunner.py", "rllib/tuned_examples/ppo/multi_agent_pendulum_ppo_envrunner.py", "rllib/tuned_examples/ppo/pendulum_ppo_envrunner.py", "rllib/tuned_examples/sac/pendulum_sac_envrunner.py", "rllib/utils/metrics/__init__.py", "rllib/utils/metrics/metrics_logger.py", "rllib/utils/metrics/stats.py", "rllib/utils/nested_dict.py", "rllib/utils/replay_buffers/prioritized_episode_replay_buffer.py", "rllib/utils/replay_buffers/utils.py", "rllib/utils/test_utils.py", ]
"type": "assert"
"numberOfMigration": ""
