"commit_hash": "986526a0e4f5ab803581074e9e4069c3edcff1dc",
"commit_link": "https://github.com/huggingface/transformers/commit/986526a0e4f5ab803581074e9e4069c3edcff1dc",
"files": ["docs/source/en/model_doc/m2m_100.mdx", "docs/source/en/model_doc/marian.mdx", "docs/source/en/model_doc/mbart.mdx", "docs/source/en/model_doc/mctct.mdx", "docs/source/en/model_doc/nllb.mdx", "docs/source/en/model_doc/plbart.mdx", "docs/source/en/model_doc/speech-encoder-decoder.mdx", "docs/source/en/model_doc/speech_to_text.mdx", "docs/source/en/model_doc/speech_to_text_2.mdx", "docs/source/en/model_doc/trocr.mdx", "docs/source/en/model_doc/wav2vec2.mdx", "docs/source/en/preprocessing.mdx", "docs/source/en/tasks/asr.mdx", "docs/source/en/tasks/summarization.mdx", "docs/source/en/tasks/translation.mdx", "docs/source/es/preprocessing.mdx", "docs/source/it/preprocessing.mdx", "examples/flax/image-captioning/run_image_captioning_flax.py", "examples/flax/summarization/run_summarization_flax.py", "examples/pytorch/question-answering/run_seq2seq_qa.py", "examples/pytorch/speech-recognition/run_speech_recognition_ctc.py", "examples/pytorch/summarization/run_summarization.py", "examples/pytorch/summarization/run_summarization_no_trainer.py", "examples/pytorch/translation/run_translation.py", "examples/pytorch/translation/run_translation_no_trainer.py", "examples/research_projects/robust-speech-event/run_speech_recognition_ctc_bnb.py", "examples/research_projects/robust-speech-event/run_speech_recognition_ctc_streaming.py", "examples/research_projects/tapex/run_wikisql_with_tapex.py", "examples/research_projects/tapex/run_wikitablequestions_with_tapex.py", "examples/research_projects/wav2vec2/run_asr.py", "examples/research_projects/wav2vec2/run_common_voice.py", "examples/research_projects/xtreme-s/run_xtreme_s.py", "examples/tensorflow/summarization/run_summarization.py", "examples/tensorflow/translation/run_translation.py", "src/transformers/models/hubert/modeling_tf_hubert.py", "src/transformers/models/m2m_100/tokenization_m2m_100.py", "src/transformers/models/marian/tokenization_marian.py", "src/transformers/models/mbart/tokenization_mbart.py", "src/transformers/models/mbart/tokenization_mbart_fast.py", "src/transformers/models/mbart50/tokenization_mbart50.py", "src/transformers/models/mbart50/tokenization_mbart50_fast.py", "src/transformers/models/mctct/processing_mctct.py", "src/transformers/models/mt5/modeling_flax_mt5.py", "src/transformers/models/mt5/modeling_mt5.py", "src/transformers/models/mt5/modeling_tf_mt5.py", "src/transformers/models/nllb/tokenization_nllb.py", "src/transformers/models/nllb/tokenization_nllb_fast.py", "src/transformers/models/plbart/tokenization_plbart.py", "src/transformers/models/rag/modeling_rag.py", "src/transformers/models/rag/tokenization_rag.py", "src/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py", "src/transformers/models/speech_to_text/processing_speech_to_text.py", "src/transformers/models/speech_to_text_2/processing_speech_to_text_2.py", "src/transformers/models/tapex/tokenization_tapex.py", "src/transformers/models/trocr/processing_trocr.py", "src/transformers/models/wav2vec2/modeling_tf_wav2vec2.py", "src/transformers/models/wav2vec2/processing_wav2vec2.py", "src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py", "src/transformers/tokenization_utils_base.py", "src/transformers/utils/doc.py", "tests/models/bart/test_tokenization_bart.py", "tests/models/byt5/test_tokenization_byt5.py", "tests/models/canine/test_tokenization_canine.py", "tests/models/dpr/test_tokenization_dpr.py", "tests/models/m2m_100/test_tokenization_m2m_100.py", "tests/models/marian/test_modeling_marian.py", "tests/models/marian/test_tokenization_marian.py", "tests/models/mbart/test_tokenization_mbart.py", "tests/models/mbart50/test_tokenization_mbart50.py", "tests/models/mctct/test_processor_mctct.py", "tests/models/mvp/test_tokenization_mvp.py", "tests/models/nllb/test_tokenization_nllb.py", "tests/models/pegasus/test_tokenization_pegasus.py", "tests/models/perceiver/test_tokenization_perceiver.py", "tests/models/plbart/test_tokenization_plbart.py", "tests/models/speech_to_text/test_processor_speech_to_text.py", "tests/models/t5/test_tokenization_t5.py", "tests/models/tapex/test_tokenization_tapex.py", "tests/models/wav2vec2/test_processor_wav2vec2.py", "tests/models/wav2vec2_with_lm/test_processor_wav2vec2_with_lm.py", ]
"type": "assert"
"numberOfMigration": ""
